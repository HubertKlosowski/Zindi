{
 "cells": [
  {
   "cell_type": "code",
   "id": "fab525021207f8ad",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wczytanie danych",
   "id": "1bfd290735c3b2e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = pd.read_csv(os.path.join('data', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('data', 'test.csv'))\n",
    "# train_additional = pd.read_csv(os.path.join('data', 'train_layer.csv'))\n",
    "\n",
    "# train_additional.info()"
   ],
   "id": "ff47ed9db9745c15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.info()",
   "id": "ce58a6da1ddd875d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rozbicie daty na składowe",
   "id": "3a18f5123a735c7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def change_date(dataframe, sin_cos=True):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['dayofweek'] = dataframe['date'].dt.dayofweek.astype(np.int64)\n",
    "    dataframe['week'] = dataframe['date'].dt.isocalendar().week.astype(np.int64)\n",
    "    dataframe['year'] = dataframe['date'].dt.year.astype(np.int64)\n",
    "    if 'month' not in dataframe.columns:\n",
    "        dataframe['month'] = dataframe['date'].dt.month.astype(np.int64)\n",
    "    # if sin_cos:\n",
    "    #     dataframe['sin_dayofweek'] = np.sin(2 * np.pi * dataframe['dayofweek'] / 7)\n",
    "    #     dataframe['cos_dayofweek'] = np.cos(2 * np.pi * dataframe['dayofweek'] / 7)\n",
    "    #     dataframe['sin_week'] = np.sin(2 * np.pi * dataframe['week'] / 52)\n",
    "    #     dataframe['cos_week'] = np.cos(2 * np.pi * dataframe['week'] / 52)\n",
    "    #     dataframe['sin_month'] = np.sin(2 * np.pi * dataframe['month'] / 12)\n",
    "    #     dataframe['cos_month'] = np.cos(2 * np.pi * dataframe['month'] / 12)\n",
    "        \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "train, test = change_date(train), change_date(test)\n",
    "# train = train[(train['date'] >= test['date'].min()) & (train['date'] <= test['date'].max())]\n",
    "# train.reset_index(drop=True, inplace=True)\n",
    "# train_additional = change_date(train_additional)"
   ],
   "id": "8d2c1f67577a7d8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 w zarejestrowanych godzinach",
   "id": "7c788a9b35c1fab3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='hour', y='pm2_5')\n",
    "plt.title('Jakość powietrza w poszczególnych godzinach')"
   ],
   "id": "bf974b1f6654091f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 w zależności od dnia tygodnia",
   "id": "f46748e403cbeb0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='dayofweek', y='pm2_5')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia')"
   ],
   "id": "265fd4ba0d9ddfc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 w zależności od miesiąca",
   "id": "e4107624bd3bca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='month', y='pm2_5')\n",
    "plt.title('Jakość powietrza w każdym miesiącu')"
   ],
   "id": "6a91d2e567c5484e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Korelacja wybranych kolumn z pm2_5",
   "id": "13f1f13fb9cf45d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.heatmap(train[['month', 'week', 'dayofweek', 'year', 'hour', 'site_latitude', 'site_longitude', 'cloud_surface_albedo', 'pm2_5']].corr(), annot=True, cmap='Greys')",
   "id": "d38b36ac602de2ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartości pm2_5 w poszczególnych miastach",
   "id": "b1ae741b1f38f74d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(data=train, x='date', y='pm2_5', hue='city')\n",
    "plt.title('Jakość powietrza w kolejnych dniach')"
   ],
   "id": "82be217767d850b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wartości pm2_5 dla Lagos z podziałem na site_id",
   "id": "7711c20595ed298b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "only_lagos = train[train['city'] == 'Lagos'][['site_id', 'pm2_5']]\n",
    "\n",
    "only_lagos.plot(kind='hist', x='site_id')"
   ],
   "id": "902609d563e3bb36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Kolumna ozone_o3_effective_temperature",
   "id": "7d44cd37e06dd943"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train['ozone_o3_effective_temperature'].describe()",
   "id": "1aa0e9c40dab5d5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ozone_o3_effective_temperature = train.loc[train['ozone_o3_effective_temperature'].isna(), ['city', 'week', 'dayofweek', 'month', 'pm2_5']].copy(deep=True)",
   "id": "8809e4b5b04f8e06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ozone_o3_effective_temperature.groupby('city')['month'].value_counts()",
   "id": "546456ca6493cec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.groupby(['city', 'month'])['ozone_o3_effective_temperature'].mean()",
   "id": "e2a0dada3f9334e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## <center>Czyszczenie danych</center>\n",
    "### Usunięcie wszystkich kolumn od sensor\n",
    "\n",
    "możliwa zależność z położeniem miasta"
   ],
   "id": "15ed92155a919761"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train.drop(columns=[column for column in train.columns if 'sensor_zenith' in column or 'sensor_azimuth' in column], inplace=True)\n",
    "test.drop(columns=[column for column in test.columns if 'sensor_zenith' in column or 'sensor_azimuth' in column], inplace=True)"
   ],
   "id": "91aca29d78476fee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Imputacja, usuwanie kolumn, oraz inne cuda",
   "id": "edbdf2d6e665b166"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "def fill_train(column_name='dayofweek'):\n",
    "    column_values = train[column_name].unique()\n",
    "    for date_unit in column_values:\n",
    "        for i, col in enumerate(starts_with):\n",
    "            similar_columns = [col for col in train.columns if col.startswith(col)]\n",
    "            df = train.loc[train[column_name] == date_unit, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                try:\n",
    "                    train.loc[train[column_name] == date_unit, similar_columns] = imputers[i].fit_transform(df)\n",
    "                except ValueError:\n",
    "                    train.drop(index=df.index, inplace=True)\n",
    "                    train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def fill_test(column_name='dayofweek'):\n",
    "    column_values = test[column_name].unique()\n",
    "    for date_unit in column_values:\n",
    "        for i, col in enumerate(starts_with):\n",
    "            similar_columns = [col for col in test.columns if col.startswith(col)]\n",
    "            df = test.loc[test[column_name] == date_unit, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                test.loc[test[column_name] == date_unit, similar_columns] = imputers[i].transform(df)\n",
    "\n",
    "def drop_high_nans():\n",
    "    columns_nans = []\n",
    "    for i, el in enumerate(train.columns):\n",
    "        if train[el].isna().sum() / len(train) >= 0.9:\n",
    "            columns_nans.append(el)\n",
    "    return columns_nans\n",
    "\n",
    "def drop_high_correlated_columns():\n",
    "    matrix = train.corr(numeric_only=True).abs()\n",
    "    upper_t = matrix.where(np.triu(np.ones_like(matrix, dtype=np.bool_), k=1))\n",
    "    return [col for col in upper_t.columns if any(upper_t[col] > 0.99)]\n",
    "\n",
    "def drop_low_correlated_columns_to_pm2_5():\n",
    "    corr = train.corr(numeric_only=True)['pm2_5'].to_frame()\n",
    "    return corr[(corr['pm2_5'] < 0.01) & (corr['pm2_5'] > -0.01)].index.to_numpy()\n",
    "\n",
    "def merge_azimuth_zenith(dataframe):\n",
    "    zenith_columns = [zenith for zenith in dataframe.columns if 'zenith' in zenith]\n",
    "    azimuth_columns = [azimuth for azimuth in dataframe.columns if 'azimuth' in azimuth]\n",
    "    for i, zenith in enumerate(zenith_columns):\n",
    "        splitted = zenith.split('_')\n",
    "        dataframe[f'{splitted[0]}_{splitted[1]}_merged'] = dataframe[zenith] * dataframe[azimuth_columns[i]]\n",
    "        dataframe.drop(zenith_columns[i], axis=1, inplace=True)\n",
    "        dataframe.drop(azimuth_columns[i], axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "starts_with = train.columns.str.split('_', expand=True).levels[0].to_frame()\n",
    "starts_with.drop(['month', 'pm2', 'id', 'city', 'date', 'country', 'site', 'hour', 'week', 'year', 'dayofweek'], inplace=True)\n",
    "starts_with = starts_with[0].tolist()\n",
    "\n",
    "imputers = [KNNImputer(n_neighbors=15, weights='distance') for _ in range(len(starts_with))]\n",
    "high_nans = drop_high_nans()\n",
    "train, test = train.drop(columns=high_nans, axis=1), test.drop(columns=high_nans, axis=1)\n",
    "# fill_train(), fill_test()\n",
    "# to_drop = drop_low_correlated_columns_to_pm2_5()\n",
    "# to_drop = np.concatenate((to_drop, drop_high_correlated_columns()), axis=0)\n",
    "# train, test = train.drop(columns=to_drop, axis=1), test.drop(columns=to_drop, axis=1)\n",
    "# train, test = merge_azimuth_zenith(train), merge_azimuth_zenith(test)\n",
    "\n",
    "train.info()"
   ],
   "id": "4cf45820641da986",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imputacja danych przy użyciu dat",
   "id": "dbb65ee72ced696b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import calendar\n",
    "\n",
    "\n",
    "def draw_calendar(dates_to_highlight, year):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    cal = calendar.Calendar(firstweekday=0)\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=3, figsize=(15, 10))\n",
    "    for m in range(12):\n",
    "        x, y = divmod(m, 3)\n",
    "        month_days = cal.monthdayscalendar(year, m + 1)\n",
    "        \n",
    "        ax[x, y].set_xlim(0, 7)\n",
    "        ax[x, y].set_ylim(0, len(month_days))\n",
    "        \n",
    "        ax[x, y].axis('off')\n",
    "        \n",
    "        days_of_week = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "        for i, day in enumerate(days_of_week):\n",
    "            ax[x, y].text(i + 0.5, len(month_days) - 0.5, day, ha='center', va='center', weight='bold')\n",
    "        \n",
    "        for r, week in enumerate(month_days):\n",
    "            for c, day in enumerate(week):\n",
    "                if day != 0:\n",
    "                    date_unit = pd.Timestamp(year, m + 1, day)\n",
    "                    highlight = date_unit in dates_to_highlight\n",
    "                    ax[x, y].text(c + 0.5, len(month_days) - r - 1.5, day, ha='center', va='center', \n",
    "                            bbox=dict(facecolor='red' if highlight else 'white', edgecolor='black'))\n",
    "        ax[x, y].set_title(f'Calendar {calendar.month_name[m + 1]} {year}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "columns_worth_filling = [col for col in train.columns if train[col].isna().sum() != 0 and 0.5 < (train[col].notna().sum() / len(train)) < 0.9]\n",
    "draw_calendar(set(train.loc[train['carbonmonoxide_co_column_number_density'].isna(), 'date']), year=2023)"
   ],
   "id": "b7b513a5b52ecffa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ACF, PACF",
   "id": "16086f0a6dc7968b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "\n",
    "def plot_correlations():\n",
    "    split_worth_filling = [[col for col in columns_worth_filling if start_with in col] for start_with in starts_with]\n",
    "    split_worth_filling = [lst for lst in split_worth_filling if lst]\n",
    "    for to_plot in split_worth_filling:\n",
    "        fig, ax = plt.subplots(nrows=len(to_plot), ncols=2, figsize=(15, 30))\n",
    "        for i, col in enumerate(to_plot):\n",
    "            plot_acf(\n",
    "                x=train[col],\n",
    "                ax=ax[i, 0],\n",
    "                missing='drop',\n",
    "                title=f'ACF of {col}',\n",
    "            )\n",
    "            plot_pacf(\n",
    "                x=train[col].dropna(),\n",
    "                ax=ax[i, 1],\n",
    "                title=f'PACF of {col}',\n",
    "            )\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "plot_correlations()"
   ],
   "id": "337db2bc9fc644c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wybór kolumn do wypełnienia danymi",
   "id": "615a169f389faf09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "choosen_ones = [column for column in train.columns if '_solar_azimuth_angle' in column] + ['cloud_surface_albedo']",
   "id": "6813584f57bc61fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Przed imputacją",
   "id": "757c5ff4c81f3c7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_choosen_ones():\n",
    "    fig, ax = plt.subplots(nrows=len(choosen_ones) // 4, ncols=4, figsize=(45, 30))\n",
    "    for i, col in enumerate(choosen_ones):\n",
    "        x, y = divmod(i, 4)\n",
    "        sns.lineplot(data=train.loc[:, ['date', 'city', col]], x='date', y=col, hue='city', ax=ax[x, y])\n",
    "        ax[x, y].set_title(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# plot_choosen_ones()"
   ],
   "id": "8ef521a5aa313a45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sprawdzenie czy szereg jest stacjonarny",
   "id": "416f42f189d11dda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "if_stationary = [{column: adfuller(train[column].dropna())} for column in choosen_ones]"
   ],
   "id": "3ae78a03c7119697",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imputacja przy wykorzystaniu ARIMA",
   "id": "c38b2b55c6e88384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# \n",
    "# \n",
    "# cities = train['city'].unique()\n",
    "# for column in choosen_ones:\n",
    "#     for city in cities:\n",
    "#         data = train.loc[train['city'] == city, ['date', column]].groupby('date').mean()\n",
    "#         data.index = pd.DatetimeIndex(data.index).to_period('D')\n",
    "#         impute_model = ARIMA(\n",
    "#             endog=data,\n",
    "#             order=(1, 0, 1),\n",
    "#             missing='none'\n",
    "#         ).fit()\n",
    "#         \n",
    "#         na_dates = data.loc[data[column].isna(), :].index\n",
    "#         for date in na_dates:\n",
    "#             data.at[pd.to_datetime(pd.to_datetime(str(date))), column] = impute_model.predict(start=date, end=date).values[0]\n",
    "#             \n",
    "#         for index, value in data.iterrows():\n",
    "#             train.loc[(train['date'] == pd.to_datetime(str(index))) & (train['city'] == city), column] = value.iloc[0]"
   ],
   "id": "49e6bd3804c7b5ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Po imputacji",
   "id": "23470236db3e6d81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# plot_choosen_ones()",
   "id": "328862e6defe0d50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Połączenie danych z innych konkursów",
   "id": "80ffbbc967cc015b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.info()",
   "id": "81a9005ec2b73b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykresy pudełkowe wskazujące wartości odstające",
   "id": "f4dc17aac706bbd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sympy import divisors\n",
    "\n",
    "\n",
    "def plot_boxplots():\n",
    "    for i, column_group in enumerate(starts_with):\n",
    "        similar_columns = [col for col in train.columns if col.startswith(column_group)]\n",
    "        if len(similar_columns) > 1:\n",
    "            divs = divisors(len(similar_columns))\n",
    "            if len(divs) % 2 == 0:\n",
    "                rows, cols = divs[(len(divs) // 2) - 1], divs[len(divs) // 2]\n",
    "            else:\n",
    "                rows, cols = divs[len(divs) // 2], divs[len(divs) // 2]\n",
    "            fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(40, 30), squeeze=False)\n",
    "            fig.suptitle(column_group, fontsize=25)\n",
    "            for j, col in enumerate(similar_columns):\n",
    "                x_cord, y_cord = divmod(j, cols)\n",
    "                train[col].plot(kind='box', ax=ax[x_cord, y_cord], fontsize=15)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "vertical_columns = [col for col in train.columns if 'number_density' in col]\n",
    "\n",
    "# plot_boxplots()"
   ],
   "id": "67e9875241d501a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Wskazanie kwantyli, od których są outliery",
   "id": "3ac24b44e6bd3a85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "detect_outliers = zscore(train['pm2_5'])\n",
    "\n",
    "quantiles = pd.DataFrame(list(zip(np.linspace(0.97, 1, 21), [np.quantile(detect_outliers, el) for el in np.linspace(0.97, 1, 21)], [np.quantile(train['pm2_5'], el) for el in np.linspace(0.97, 1, 21)])), columns=['quantile', 'zscore', 'pm2_5'])\n",
    "quantiles"
   ],
   "id": "e7d3f816a2bb205d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Usunięcie wartości odstających",
   "id": "24c6669735dee8d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def del_pm2_5_outliers():\n",
    "    indexes_to_drop = []\n",
    "    q1, q2 = np.quantile(detect_outliers, 0.01), np.quantile(detect_outliers, 0.99)\n",
    "    for i, el in enumerate(detect_outliers):\n",
    "        if el > q2:\n",
    "            indexes_to_drop.append(i)\n",
    "    train.drop(indexes_to_drop, inplace=True)\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "def cap_pm2_5_outliers():\n",
    "    to_cap = np.quantile(detect_outliers, 0.99) * train['pm2_5'].std()\n",
    "    train['pm2_5'] = train['pm2_5'].clip(upper=to_cap)\n",
    "\n",
    "\n",
    "del_pm2_5_outliers()\n",
    "# cap_pm2_5_outliers()\n",
    "\n",
    "train.info()"
   ],
   "id": "a3c1c6860a3b0de4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Usuwanie outlierów na podstawie rady marching_learning",
   "id": "da5a062992a03500"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "joined = pd.merge(only_lagos, detect_outliers, left_index=True, right_index=True)\n",
    "outliers_from_lagos = joined[joined['pm2_5_y'] > 3.0]['site_id'].value_counts()\n",
    "site_ids_to_del = outliers_from_lagos.keys()[:2]\n",
    "outliers_from_lagos"
   ],
   "id": "5f37ea49ec020e3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# indexes = train[train['site_id'].isin(site_ids_to_del)].index\n",
    "# train.drop(index=indexes, inplace=True)\n",
    "# train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# train.info()"
   ],
   "id": "c152f1e37847488a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Limit wartości dla kolumn uvaerosolindex_sensor_altitude\n",
    "ustawienie zakresu z zbioru test"
   ],
   "id": "e60d63f94b8462ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# limit = train.loc[(test['uvaerosolindex_sensor_altitude'].min() < train['uvaerosolindex_sensor_altitude']) & (train['uvaerosolindex_sensor_altitude'] > test['uvaerosolindex_sensor_altitude'].max()), :].index\n",
    "# train.drop(index=limit, inplace=True)\n",
    "# train.reset_index(drop=True, inplace=True)"
   ],
   "id": "d462302c8dc3bf20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Selekcja cech</center>",
   "id": "aa4a1dd941bba4fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest, mutual_info_regression, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def plot_feature_importance(sc, num_of_features):\n",
    "    if isinstance(sc, RFECV) or isinstance(sc, RFE):\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.ranking_))\n",
    "    else:\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.scores_))\n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:num_of_features]\n",
    "    scores_df = pd.DataFrame(scores, columns=['Feature', 'Score'])\n",
    "\n",
    "    scores_df.plot(kind='bar', x='Feature', y='Score', figsize=(10, 6), rot=90, title='Oceny wybranych cech')\n",
    "    plt.xlabel('Cecha')\n",
    "    plt.ylabel('Ocena')\n",
    "\n",
    "\n",
    "# selector = RFE(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=700, \n",
    "#         max_depth=7, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True,\n",
    "#         warm_start=True\n",
    "#     ),\n",
    "#     n_features_to_select=k,\n",
    "# )\n",
    "# k = 17\n",
    "# selector = RFECV(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=400, \n",
    "#         max_depth=10, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True, \n",
    "#         warm_start=True, \n",
    "#         ccp_alpha=1e-4\n",
    "#     ),\n",
    "#     min_features_to_select=k, \n",
    "#     cv=10, \n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# selector.fit(train, y)\n",
    "# train, test = selector.transform(train), selector.transform(test)\n",
    "# \n",
    "# plot_feature_importance(selector, k)"
   ],
   "id": "b5b7d04884cab66d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## <center>Transformacja danych</center>\n",
    "### 1. Standaryzacja danych"
   ],
   "id": "3cdd37ba5459c448"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, TargetEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "test_ids = test['id']\n",
    "train.drop(columns=['id', 'city', 'date', 'country', 'site_id', 'site_latitude', 'site_longitude', 'hour'], inplace=True)\n",
    "test.drop(columns=['id', 'city', 'date', 'country', 'site_id', 'site_latitude', 'site_longitude', 'hour'], inplace=True)\n",
    "\n",
    "train_pm2_5 = train['pm2_5']\n",
    "train.drop(columns=['pm2_5'], inplace=True)"
   ],
   "id": "b588a29d657f3df7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Z podziałem na kategoryczne",
   "id": "82aa10574502435d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# categorical = ['month', 'dayofweek', 'week', 'year']\n",
    "# train[categorical] = train[categorical].astype('category')\n",
    "# test[categorical] = test[categorical].astype('category')\n",
    "# \n",
    "# non_cat_columns = train.columns.difference(categorical)\n",
    "# \n",
    "# non_cat_scaler = make_column_transformer((RobustScaler(), non_cat_columns))\n",
    "# te = TargetEncoder(random_state=4)\n",
    "# \n",
    "# train_cat, test_cat = te.fit_transform(train[categorical], train_pm2_5), te.transform(test[categorical])\n",
    "# \n",
    "# train = pd.concat([pd.DataFrame(non_cat_scaler.fit_transform(train[non_cat_columns]), columns=non_cat_scaler.feature_names_in_), pd.DataFrame(train_cat, columns=te.feature_names_in_), train_pm2_5], axis=1)\n",
    "# test = pd.concat([test_ids, pd.DataFrame(non_cat_scaler.transform(test[non_cat_columns]), columns=non_cat_scaler.feature_names_in_), pd.DataFrame(test_cat, columns=te.feature_names_in_)], axis=1)\n",
    "\n",
    "# train = train.round(decimals=3)"
   ],
   "id": "cf6c24f2f6db0a83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Wszystkie kolumny",
   "id": "2dd23a2050be5bc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train, test = scaler.fit_transform(train), scaler.transform(test)\n",
    "train, test = pd.concat([pd.DataFrame(train, columns=scaler.feature_names_in_), train_pm2_5], axis=1), pd.concat([test_ids, pd.DataFrame(test, columns=scaler.feature_names_in_)], axis=1)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zapis przekształconych danych",
   "id": "f39e5e9b5d6db6f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'transform' not in os.listdir(os.getcwd()):\n",
    "    os.mkdir('transform')\n",
    "train.to_csv(os.path.join('transform', 'train.csv'), index=False)\n",
    "test.to_csv(os.path.join('transform', 'test.csv'), index=False)"
   ],
   "id": "6fe27a6a613d3b3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.info()",
   "id": "b9cde137a4fa5773",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test.info()",
   "id": "d37364bf0c1f3c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Po prostu xd",
   "id": "26cb836f54ab6642"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xd = pd.read_csv(os.path.join('data', 'lightgbm.csv'), header=0)\n",
    "xd['pm2_5'] *= 0.99\n",
    "xd.to_csv(os.path.join('data', 'lightgbm_even_better.csv'), index=False)"
   ],
   "id": "27b4bead0508e55f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
