{
 "cells": [
  {
   "cell_type": "code",
   "id": "fab525021207f8ad",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wczytanie danych",
   "id": "1bfd290735c3b2e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = pd.read_csv(os.path.join('data', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('data', 'test.csv'))\n",
    "\n",
    "train.info()"
   ],
   "id": "ce58a6da1ddd875d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.head()",
   "id": "515b618d3712eac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rozbicie daty na składowe",
   "id": "3a18f5123a735c7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def change_date(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['dayofweek'] = dataframe['date'].dt.dayofweek.astype('category')\n",
    "    dataframe['week'] = dataframe['date'].dt.isocalendar().week.astype('category')\n",
    "    dataframe['month'] = dataframe['month'].astype('category')\n",
    "    dataframe['quater'] = dataframe['date'].dt.quarter.astype('category')\n",
    "    dataframe['hour'] = dataframe['hour'].astype('category')\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "train, test = change_date(train), change_date(test)"
   ],
   "id": "8d2c1f67577a7d8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykrs przedstawiający wartość pm2_5 w kolejnych kwartałach roku",
   "id": "808756317694a80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='quater', y='pm2_5')\n",
    "plt.title('Jakość powietrza w kwartałach')"
   ],
   "id": "d9aad1ad215ccd55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający jakość powietrza w krajach afrykańskich",
   "id": "85edb84c8e895e99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.lineplot(data=train, x='date', y='pm2_5')\n",
    "plt.title('Jakość powietrza w kolejnych dniach')"
   ],
   "id": "edbef352ee06ce32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 w zarejestrowanych godzinach",
   "id": "7c788a9b35c1fab3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='hour', y='pm2_5')\n",
    "plt.title('Jakość powietrza w poszczególnych godzinach')"
   ],
   "id": "bf974b1f6654091f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 w zależności od dnia tygodnia",
   "id": "f46748e403cbeb0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='dayofweek', y='pm2_5')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia')"
   ],
   "id": "265fd4ba0d9ddfc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 w zależności od miesiąca",
   "id": "e4107624bd3bca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='month', y='pm2_5')\n",
    "plt.title('Jakość powietrza w każdym miesiącu')"
   ],
   "id": "6a91d2e567c5484e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Korelacja wybranych kolumn z pm2_5",
   "id": "13f1f13fb9cf45d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.heatmap(train[['month', 'dayofweek', 'hour', 'site_latitude', 'site_longitude', 'cloud_surface_albedo', 'quater', 'pm2_5']].corr(), annot=True, cmap='Greys')",
   "id": "d38b36ac602de2ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## <center>Czyszczenie danych</center>\n",
    "### 1. Imputacja, usuwanie kolumn, oraz inne cuda"
   ],
   "id": "15ed92155a919761"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "def fill_x(column_name='site_latitude'):\n",
    "    column_values = train[column_name].unique()\n",
    "    for date in column_values:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [col for col in train.columns if col.startswith(column)]\n",
    "            df = train.loc[train[column_name] == date, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                try:\n",
    "                    train.loc[train[column_name] == date, similar_columns] = imputers[i].fit_transform(df)\n",
    "                except ValueError:\n",
    "                    train.drop(index=df.index, inplace=True)\n",
    "                    train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def fill_test(column_name='site_latitude'):\n",
    "    column_values = test[column_name].unique()\n",
    "    for date in column_values:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [col for col in test.columns if col.startswith(column)]\n",
    "            df = test.loc[test[column_name] == date, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                test.loc[test[column_name] == date, similar_columns] = imputers[i].transform(df)\n",
    "\n",
    "def drop_high_nans(dataframe):  # usuwamy kolumny o dużej liczbie wartości NaN\n",
    "    columns_nans = []\n",
    "    for i, el in enumerate(dataframe.columns):\n",
    "        if dataframe[el].isna().sum() / len(dataframe) >= 0.9:\n",
    "            columns_nans.append(el)\n",
    "    dataframe.drop(columns_nans, axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def drop_high_correlated_columns():\n",
    "    matrix = train.corr(numeric_only=True).abs()\n",
    "    upper_t = matrix.where(np.triu(np.ones_like(matrix, dtype=np.bool_), k=1))\n",
    "    return [col for col in upper_t.columns if any(upper_t[col] > 0.99)]\n",
    "\n",
    "def drop_low_correlated_columns_to_pm2_5():\n",
    "    corr = train.corr()['pm2_5'].to_frame()\n",
    "    return corr[(corr['pm2_5'] < 0.01) & (corr['pm2_5'] > -0.01)].index.to_numpy()\n",
    "\n",
    "def subract_azimuth_zenith(dataframe):\n",
    "    zenith_columns = [zenith for zenith in dataframe.columns if 'zenith' in zenith]\n",
    "    azimuth_columns = [azimuth for azimuth in dataframe.columns if 'azimuth' in azimuth]\n",
    "    for i, zenith in enumerate(zenith_columns):\n",
    "        splitted = zenith.split('_')\n",
    "        dataframe[f'{splitted[0]}_{splitted[1]}_diff'] = dataframe[zenith] - dataframe[azimuth_columns[i]]\n",
    "        dataframe.drop(zenith_columns[i], axis=1, inplace=True)\n",
    "        dataframe.drop(azimuth_columns[i], axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def change_to_categorical():\n",
    "    for column in categorical:\n",
    "        train[column] = train[column].astype('category')\n",
    "        test[column] = test[column].astype('category')\n",
    "\n",
    "\n",
    "categorical = ['hour', 'month', 'dayofweek', 'site_latitude', 'site_longitude']\n",
    "test_ids = test['id']\n",
    "train.drop(columns=['id', 'city', 'country', 'date', 'site_id'], inplace=True)\n",
    "test.drop(columns=['id', 'city', 'country', 'date', 'site_id'], inplace=True)\n",
    "starts_with = train.columns.str.split('_', expand=True).levels[0].to_frame()\n",
    "starts_with.drop(['month', 'hour', 'pm2', 'site'], inplace=True)\n",
    "starts_with = starts_with[0].tolist()\n",
    "\n",
    "imputers = [KNNImputer(n_neighbors=15, weights='distance') for _ in range(len(starts_with))]\n",
    "train, test = drop_high_nans(train), drop_high_nans(test)\n",
    "change_to_categorical()\n",
    "# fill_x(), fill_test()\n",
    "to_drop = drop_low_correlated_columns_to_pm2_5()\n",
    "to_drop = np.concatenate((to_drop, drop_high_correlated_columns()), axis=0)\n",
    "train, test = train.drop(columns=to_drop, axis=1), test.drop(columns=to_drop, axis=1)\n",
    "# train, test = subract_azimuth_zenith(train), subract_azimuth_zenith(test)"
   ],
   "id": "cba91ead48820415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykresy pudełkowe wskazujące wartości odstające",
   "id": "f4dc17aac706bbd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sympy import divisors\n",
    "\n",
    "\n",
    "def plot_boxplots():\n",
    "    for i, column_group in enumerate(starts_with):\n",
    "        similar_columns = [col for col in train.columns if col.startswith(column_group)]\n",
    "        if len(similar_columns) > 1:\n",
    "            divs = divisors(len(similar_columns))\n",
    "            if len(divs) % 2 == 0:\n",
    "                rows, cols = divs[(len(divs) // 2) - 1], divs[len(divs) // 2]\n",
    "            else:\n",
    "                rows, cols = divs[len(divs) // 2], divs[len(divs) // 2]\n",
    "            fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(40, 30), squeeze=False)\n",
    "            fig.suptitle(column_group, fontsize=25)\n",
    "            for j, column in enumerate(similar_columns):\n",
    "                x_cord, y_cord = divmod(j, cols)\n",
    "                train[column].plot(kind='box', ax=ax[x_cord, y_cord], fontsize=15)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "vertical_columns = [col for col in train.columns if 'number_density' in col]\n",
    "\n",
    "# plot_boxplots()"
   ],
   "id": "67e9875241d501a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Wskazanie kwantyli, od których są outliery",
   "id": "3ac24b44e6bd3a85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "detect_outliers = zscore(train['pm2_5'])\n",
    "\n",
    "quantiles = pd.DataFrame(list(zip(np.linspace(0.9, 1, 20), [np.quantile(detect_outliers, el) for el in np.linspace(0.9, 1, 20)])), columns=['quantile', 'zscore'])\n",
    "quantiles"
   ],
   "id": "e7d3f816a2bb205d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Usunięcie wartości odstających",
   "id": "24c6669735dee8d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def del_pm2_5_outliers():\n",
    "    indexes_to_drop = []\n",
    "    q1, q2 = np.quantile(detect_outliers, 0.01), np.quantile(detect_outliers, 0.95)\n",
    "    for i, el in enumerate(detect_outliers):\n",
    "        if q1 < el > q2:\n",
    "            indexes_to_drop.append(i)\n",
    "    train.drop(indexes_to_drop, inplace=True)\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "del_pm2_5_outliers()\n",
    "\n",
    "train.info()"
   ],
   "id": "a3c1c6860a3b0de4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.head()",
   "id": "51f8620d8a1e1e28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Selekcja cech</center>",
   "id": "aa4a1dd941bba4fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest, mutual_info_regression, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def plot_feature_importance(sc, num_of_features):\n",
    "    if isinstance(sc, RFECV) or isinstance(sc, RFE):\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.ranking_))\n",
    "    else:\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.scores_))\n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:num_of_features]\n",
    "    scores_df = pd.DataFrame(scores, columns=['Feature', 'Score'])\n",
    "\n",
    "    scores_df.plot(kind='bar', x='Feature', y='Score', figsize=(10, 6), rot=90, title='Oceny wybranych cech')\n",
    "    plt.xlabel('Cecha')\n",
    "    plt.ylabel('Ocena')\n",
    "\n",
    "\n",
    "# selector = RFE(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=700, \n",
    "#         max_depth=7, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True,\n",
    "#         warm_start=True\n",
    "#     ),\n",
    "#     n_features_to_select=k,\n",
    "# )\n",
    "# k = 17\n",
    "# selector = RFECV(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=400, \n",
    "#         max_depth=10, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True, \n",
    "#         warm_start=True, \n",
    "#         ccp_alpha=1e-4\n",
    "#     ),\n",
    "#     min_features_to_select=k, \n",
    "#     cv=10, \n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# selector.fit(train, y)\n",
    "# train, test = selector.transform(train), selector.transform(test)\n",
    "# \n",
    "# plot_feature_importance(selector, k)"
   ],
   "id": "b5b7d04884cab66d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## <center>Transformacja danych</center>\n",
    "### 1. Standaryzacja danych"
   ],
   "id": "3cdd37ba5459c448"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Bez kategorycznych\n",
    "# scale_columns = train.columns.difference(categorical)\n",
    "# \n",
    "# scaler = make_column_transformer((StandardScaler(), scale_columns))\n",
    "# \n",
    "# X_cat, test_cat = train[categorical], test[categorical]\n",
    "# \n",
    "# train = pd.concat([pd.DataFrame(scaler.fit_transform(train[scale_columns]), columns=scaler.feature_names_in_), X_cat], axis=1)\n",
    "# test = pd.concat([pd.DataFrame(scaler.transform(test[scale_columns]), columns=scaler.feature_names_in_), test_cat], axis=1)\n",
    "# Wszystkie kolumny\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train['pm2_5'] = train['pm2_5'].apply(lambda x: np.round(x, 3))\n",
    "train_pm2_5 = train['pm2_5']\n",
    "train, test = scaler.fit_transform(train.drop(columns='pm2_5', axis=1)), scaler.transform(test)\n",
    "train, test = pd.concat([pd.DataFrame(train, columns=scaler.feature_names_in_), train_pm2_5], axis=1), pd.concat([test_ids, pd.DataFrame(test, columns=scaler.feature_names_in_)], axis=1)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zapis przekształconych danych",
   "id": "f39e5e9b5d6db6f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'transform' not in os.listdir(os.getcwd()):\n",
    "    os.mkdir('transform')\n",
    "train.to_csv(os.path.join('transform', 'train.csv'), index=False)\n",
    "test.to_csv(os.path.join('transform', 'test.csv'), index=False)"
   ],
   "id": "6fe27a6a613d3b3a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
