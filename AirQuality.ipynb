{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Analiza poziomu PM2.5 w afrykańskich miastach</center>\n",
    "### Zespół:\n",
    "<ol>\n",
    "    <li style='font-size: 20px'>Hubert Kłosowski 242424</li>\n",
    "    <li style='font-size: 20px'>Krzysztof Kolanek 242425</li>\n",
    "    <li style='font-size: 20px'>Kamil Małecki 242464</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a096af4d2cacc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potrzebne importy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a57b6008c92140"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f44b8667be4021ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wczytanie danych"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c7a6517c9f58e8"
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('data\\\\Train.csv')\n",
    "test = pd.read_csv('data\\\\Test.csv')\n",
    "\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8195eb62bb5596b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcef3f3066b6dcaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rozbicie daty na składowe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af49ecab4176ea4c"
  },
  {
   "cell_type": "code",
   "source": [
    "def change_date(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['day'] = dataframe['date'].dt.dayofweek.astype(np.int64)\n",
    "    dataframe['month'] = dataframe['month'].astype(np.int64)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "data, test = change_date(data), change_date(test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96de3f55dc052fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający jakość powietrza w krajach afrykańskich"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdbb93a09da5579d"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.lineplot(data=data, x='date', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c080d74ffd38ea41",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 w zarejestrowanych godzinach"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c18ec25179e58a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=data, x='hour', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w poszczególnych godzinach z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cc187b6375c9eb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 z zależności od dnia tygodnia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4b3fd78e799e096"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=data, x='day', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36c6ec9520527975",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 z zależności od miesiąca"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c018df974513e0e3"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=data, x='month', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18b6234a9ec5ca95",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Korelacje poszczególnych grup kolumn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "785f97dcd77bdb1c"
  },
  {
   "cell_type": "code",
   "source": [
    "def correlation():\n",
    "    for index, column in enumerate(starts_with):\n",
    "        selected_columns = [col for col in data.columns if col.startswith(column) or col == 'pm2_5']\n",
    "        if len(selected_columns) > 1:\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            sns.heatmap(data[selected_columns].corr(), annot=True, fmt='.2f', cmap='viridis', ax=ax)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "def drop_high_correlated_columns(dataframe):\n",
    "    matrix = dataframe.corr(numeric_only=True)\n",
    "    upper = matrix.where(np.triu(np.ones(matrix.shape), k=1).astype(np.bool_))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] >= 0.9)]\n",
    "    return dataframe.drop(to_drop, axis=1)\n",
    "\n",
    "\n",
    "final_ids = test['id']\n",
    "starts_with = data.columns.str.split('_', expand=True).levels[0].to_frame()\n",
    "starts_with.drop(['month', 'day', 'hour', 'pm2'], inplace=True)\n",
    "starts_with = starts_with[0].tolist()\n",
    "data, test = drop_high_correlated_columns(data), drop_high_correlated_columns(test)\n",
    "data.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "test.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "\n",
    "correlation()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67d0ec8072327669",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Czyszczenie danych</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab3216061cba4b3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Uzupełnienie wartości brakujących"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba2f9b8e1bcb96ad"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def fill_based_on(dataframe, date_unit='day'):\n",
    "    date_range = dataframe[date_unit].unique()\n",
    "    for date in date_range:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [el for el in dataframe.columns if el.startswith(column)]\n",
    "            df = dataframe.loc[dataframe[date_unit] == date, similar_columns]\n",
    "            if not df.empty:\n",
    "                dataframe.loc[dataframe[date_unit] == date, similar_columns] = imputers[i].fit_transform(df)\n",
    "    return dataframe\n",
    "\n",
    "def prepare_dataframe(dataframe):  # usuwamy kolumny o dużej liczbie wartości NaN\n",
    "    to_drop = []\n",
    "    for index, el in enumerate(dataframe.columns):\n",
    "        if dataframe[el].isna().sum() / len(dataframe) >= 0.9:\n",
    "            to_drop.append(el)\n",
    "    dataframe.drop(to_drop, axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "imputers = [KNNImputer(n_neighbors=15, weights='distance') for _ in range(len(starts_with))]\n",
    "data, test = prepare_dataframe(data), prepare_dataframe(test)\n",
    "data, test = fill_based_on(data), fill_based_on(test)\n",
    "ver = dict(zip(['sulphurdioxide_so2_column_number_density', 'carbonmonoxide_co_column_number_density', 'nitrogendioxide_no2_column_number_density', 'nitrogendioxide_stratospheric_no2_column_number_density'], [(-0.001 / data['sulphurdioxide_so2_column_number_density'].std(), 4), (2.25, 6), (1, 10), (19.5, 26)]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "133fbc1ffe6ae43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykresy pudełkowe wskazujące wartości odstające"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9af06f017aaea4c3"
  },
  {
   "cell_type": "code",
   "source": [
    "from sympy import divisors\n",
    "\n",
    "def plot_boxplots():\n",
    "    for index, column_group in enumerate(starts_with):\n",
    "        similar_columns = [col for col in data.columns if col.startswith(column_group)]\n",
    "        if len(similar_columns) > 1:\n",
    "            divs = divisors(len(similar_columns))\n",
    "            if len(divs) % 2 == 0:\n",
    "                rows, cols = divs[(len(divs) // 2) - 1], divs[len(divs) // 2]\n",
    "            else:\n",
    "                rows, cols = divs[len(divs) // 2], divs[len(divs) // 2]\n",
    "            fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(40, 30), squeeze=False)\n",
    "            fig.suptitle(column_group, fontsize=25)\n",
    "            for j, column in enumerate(similar_columns):\n",
    "                x_cord, y_cord = divmod(j, cols)\n",
    "                data[column].plot(kind='box', ax=ax[x_cord][y_cord], fontsize=15)\n",
    "                if column in ver.keys():\n",
    "                    ax[x_cord][y_cord].axhline(y=ver.get(column)[1] * data[column].std(), color='red')\n",
    "                    ax[x_cord][y_cord].axhline(y=ver.get(column)[0] * data[column].std(), color='green')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# plot_boxplots()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7901bc4c9d7d1412",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Usunięcie wartości odstających"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a767724811d79e3c"
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def del_outliers(dataframe):\n",
    "    for column, zscore_range in ver.items():\n",
    "        vec, indexes = zscore(dataframe[column]), []\n",
    "        for j in range(len(vec)):\n",
    "            if zscore_range[0] <= vec[j] >= zscore_range[1]:\n",
    "                indexes.append(j)\n",
    "        dataframe.drop(index=indexes, inplace=True)\n",
    "        dataframe.reset_index(drop=True, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "data = del_outliers(data)\n",
    "\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e31da0f18fee574",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "data.head()",
   "metadata": {
    "collapsed": false
   },
   "id": "3463da86e8af6bd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Selekcja cech</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9161db0ea237c"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import SelectKBest, RFECV, RFE, mutual_info_regression, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def plot_feature_importance(sc, num_of_features):\n",
    "    if isinstance(sc, RFECV) or isinstance(sc, RFE):\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.ranking_))\n",
    "    else:\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.scores_))\n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:num_of_features]\n",
    "    scores_df = pd.DataFrame(scores, columns=['Feature', 'Score'])\n",
    "    \n",
    "    scores_df.plot(kind='bar', x='Feature', y='Score', figsize=(10, 6), rot=90, title='Oceny wybranych cech')\n",
    "    plt.xlabel('Cecha')\n",
    "    plt.ylabel('Ocena')\n",
    "\n",
    "\n",
    "X, y = data.drop(['pm2_5'], axis=1), data['pm2_5']\n",
    "k = 25\n",
    "selector = RFECV(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_estimators=700, \n",
    "        max_depth=7, \n",
    "        random_state=4, \n",
    "        n_jobs=-1, \n",
    "        oob_score=True,\n",
    "        warm_start=True,\n",
    "    ),\n",
    "    min_features_to_select=k, \n",
    "    cv=10, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    ")\n",
    "# selector = RFE(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=700, \n",
    "#         max_depth=7, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True,\n",
    "#         warm_start=True\n",
    "#     ),\n",
    "#     n_features_to_select=k,\n",
    "# )\n",
    "selector.fit(X, y)\n",
    "X, test = selector.transform(X), selector.transform(test)\n",
    "\n",
    "plot_feature_importance(selector, k)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c002ded9461774c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Transformacja danych</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8b9be23efdbd904"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potrzebne importy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eae50f8387e668ab"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537a6c450bd1efa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### 1. Wybór sposobu preprocessingu danych",
   "metadata": {
    "collapsed": false
   },
   "id": "22bf5b75d8429019"
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X, y)\n",
    "test = scaler.transform(test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376c12ae9287f590",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Podział na zbiór testowy i treningowy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c70912092f074e4"
  },
  {
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)",
   "metadata": {
    "collapsed": false
   },
   "id": "683541f15475f393",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Część obliczeniowa</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea367ef409a37a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potrzebne importy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5e7b079774ede3e"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc1a78b81969b11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Otrzymanie najlepszych parametrów",
   "id": "9831b50f952a24eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def give_the_best(clf):\n",
    "    gs = GridSearchCV(clf, params, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=5)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_\n",
    "\n",
    "def save_to_csv(y_pred, save_as):\n",
    "    final_df = pd.concat([final_ids, pd.DataFrame.from_dict({'pm2_5': y_pred})], axis=1)\n",
    "    final_df.to_csv(f'result\\\\{save_as}', index=False)"
   ],
   "id": "e9d2d344d5d30f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <center>Regresja przy użyciu MLP</center>",
   "id": "cc72c66908bb5e08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# params = {\n",
    "#     'hidden_layer_sizes': [(99, 141, 75)],\n",
    "#     'activation': ['relu'],\n",
    "#     'solver': ['adam'],\n",
    "#     'max_iter': [1000],\n",
    "#     'alpha': np.linspace(0.0001, 0.001, 10),\n",
    "#     'batch_size': [64, 128, 256],\n",
    "#     'learning_rate_init': np.linspace(0.001, 0.01, 10),\n",
    "#     'warm_start': [True],\n",
    "#     'early_stopping': [True],\n",
    "#     'validation_fraction': [0.1]\n",
    "# }\n",
    "# \n",
    "# mlp = give_the_best(MLPRegressor())\n",
    "# save_to_csv(mlp.predict(test), 'mlp.csv')\n",
    "# print('Parametry MLP: ', mlp.get_params())\n",
    "# print('RMSE: ', root_mean_squared_error(y_test, mlp.predict(X_test)))"
   ],
   "id": "ed5f063582c3c0e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <center>PyTorch</center>",
   "id": "d8bd09cb2fae5106"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potrzebne importy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f087e5cbcc23b0ae"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "498ea0f7dd22079c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Wybór karty graficznej do nauki modelu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaf607cc44710975"
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    'cuda'\n",
    "    if torch.cuda.is_available()\n",
    "    else 'mps'\n",
    "    if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, device=device, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, device=device, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), device=device, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), device=device, dtype=torch.float)\n",
    "test_tensor = torch.tensor(test, device=device, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ea7f2091127d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Architektura sieci neuronowej"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aff1a14b2bea3818"
  },
  {
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(X_train_tensor.shape[1], 101),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(101, 145),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(145, 45),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(45, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "def rmse_loss(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "\n",
    "model = Net().to(device=device)\n",
    "criterion = rmse_loss\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=0.001, \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-8, \n",
    "    weight_decay=1e-4, \n",
    "    amsgrad=True, \n",
    "    fused=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bbca20bcc1becc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Nauka sieci neuronowej na zbiorze treningowym"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f3f743712603d7"
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 150\n",
    "\n",
    "final_train_tensor = torch.concat((X_train_tensor, y_train_tensor.unsqueeze(dim=1)), dim=1)\n",
    "dataset = DataLoader(final_train_tensor, batch_size=batch_size, shuffle=True)\n",
    "epoch_losses = [{'epoch': i, 'rmse': 0} for i in range(num_epochs)]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, batch in enumerate(dataset):\n",
    "        inputs, targets = batch[:, :-1], batch[:, -1]\n",
    "        batch_pred = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(targets, batch_pred.squeeze())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_losses[epoch].update({'rmse': epoch_loss / len(dataset)})\n",
    "    print(f'Epoch: [{epoch + 1}/{num_epochs}] RMSE: {epoch_loss / len(dataset):.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee01653bc24ee293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Jakość sieci neuronowej",
   "id": "af467d14c745b2a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.lineplot(data=pd.DataFrame(epoch_losses), x='epoch', y='rmse')",
   "id": "a4dc6621d5974fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### 4. Testowanie sieci neuronowej",
   "metadata": {
    "collapsed": false
   },
   "id": "2f4ae6f4bd5948ff"
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(X_test_tensor)\n",
    "    loss = criterion(y_test_tensor, pred.squeeze())\n",
    "    print(f'RMSE: {loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4907fe921715dfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parametry modelu",
   "id": "d509b50d8736fc70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Parametry modelu:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "torch.save(model.state_dict(), 'model.pt')"
   ],
   "id": "c3a1775f64035a1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Do wysłania</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79bf1209e752a444"
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    final_pred = model(test_tensor)\n",
    "    save_to_csv(final_pred.squeeze().numpy(force=True), 'nn.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ce5044d06598de",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dodatkowe informacje\n",
    "<ol>\n",
    "    <li>The 15km SO2 band is ingested only when solar_zenith_angle < 70.</li>\n",
    "    <li>Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2128d77bca7e777"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
