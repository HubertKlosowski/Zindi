{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Analiza poziomu PM2.5 w afrykańskich miastach</center>\n",
    "### Zespół:\n",
    "<ol>\n",
    "    <li style='font-size: 20px'>Hubert Kłosowski 242424</li>\n",
    "    <li style='font-size: 20px'>Krzysztof Kolanek 242425</li>\n",
    "    <li style='font-size: 20px'>Kamil Małecki 242464</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a096af4d2cacc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potrzebne importy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a57b6008c92140"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from sympy import divisors\n",
    "from scipy.stats import zscore\n",
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest, mutual_info_regression, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f44b8667be4021ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wczytanie danych"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c7a6517c9f58e8"
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('data\\\\Train.csv')\n",
    "test = pd.read_csv('data\\\\Test.csv')\n",
    "\n",
    "train.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8195eb62bb5596b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "train.head()",
   "metadata": {
    "collapsed": false
   },
   "id": "dcef3f3066b6dcaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rozbicie daty na składowe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af49ecab4176ea4c"
  },
  {
   "cell_type": "code",
   "source": [
    "def change_date(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['day'] = dataframe['date'].dt.dayofweek.astype(np.int64)\n",
    "    dataframe['month'] = dataframe['month'].astype(np.int64)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "train, test = change_date(train), change_date(test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96de3f55dc052fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający jakość powietrza w krajach afrykańskich"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdbb93a09da5579d"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.lineplot(data=train, x='date', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c080d74ffd38ea41",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 w zarejestrowanych godzinach"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c18ec25179e58a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='hour', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w poszczególnych godzinach z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cc187b6375c9eb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 z zależności od dnia tygodnia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4b3fd78e799e096"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='day', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36c6ec9520527975",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 z zależności od miesiąca"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c018df974513e0e3"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='month', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18b6234a9ec5ca95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Korelacja wybranych kolumn z pm2_5",
   "id": "c2c34b8f0e6bf038"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.heatmap(train[['month', 'day', 'hour', 'site_latitude', 'site_longitude', 'pm2_5']].corr(), annot=True, cmap='Greys')",
   "id": "e9964e42a6e9e51f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Czyszczenie danych</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab3216061cba4b3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Uzupełnienie wartości brakujących"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba2f9b8e1bcb96ad"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "def fill_train(column_name='site_latitude'):\n",
    "    column_values = X[column_name].unique()\n",
    "    for date in column_values:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [col for col in X.columns if col.startswith(column)]\n",
    "            df = X.loc[X[column_name] == date, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                try:\n",
    "                    X.loc[X[column_name] == date, similar_columns] = imputers[i].fit_transform(df, y)\n",
    "                except ValueError:\n",
    "                    X.drop(index=df.index, inplace=True)\n",
    "                    y.drop(index=df.index, inplace=True)\n",
    "                    X.reset_index(drop=True, inplace=True)\n",
    "                    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def fill_test(column_name='site_latitude'):\n",
    "    column_values = test[column_name].unique()\n",
    "    for date in column_values:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [col for col in test.columns if col.startswith(column)]\n",
    "            df = test.loc[test[column_name] == date, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                test.loc[test[column_name] == date, similar_columns] = imputers[i].transform(df)\n",
    "\n",
    "def drop_high_nans(dataframe):  # usuwamy kolumny o dużej liczbie wartości NaN\n",
    "    columns_nans = []\n",
    "    for i, el in enumerate(dataframe.columns):\n",
    "        if dataframe[el].isna().sum() / len(dataframe) >= 0.9:\n",
    "            columns_nans.append(el)\n",
    "    dataframe.drop(columns_nans, axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def drop_high_correlated_columns():\n",
    "    matrix = X.corr(numeric_only=True).abs()\n",
    "    upper_t = matrix.where(np.triu(np.ones_like(matrix, dtype=np.bool_), k=1))\n",
    "    return [col for col in upper_t.columns if any(upper_t[col] > 0.9)]\n",
    "\n",
    "\n",
    "test_ids = test['id']\n",
    "train.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "test.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "starts_with = train.columns.str.split('_', expand=True).levels[0].to_frame()\n",
    "starts_with.drop(['month', 'day', 'hour', 'pm2'], inplace=True)\n",
    "starts_with = starts_with[0].tolist()\n",
    "\n",
    "imputers = [KNNImputer(n_neighbors=15, weights='distance') for _ in range(len(starts_with))]\n",
    "# imputers = [IterativeImputer() for _ in range(len(starts_with))]\n",
    "X, y = train.drop(['pm2_5'], axis=1), train['pm2_5']\n",
    "# X, test = drop_high_nans(X), drop_high_nans(test)\n",
    "# fill_train(), fill_test()\n",
    "# to_drop = drop_high_correlated_columns()\n",
    "# X, test = X.drop(columns=to_drop, axis=1), test.drop(columns=to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "133fbc1ffe6ae43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykresy pudełkowe wskazujące wartości odstające"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9af06f017aaea4c3"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_boxplots():\n",
    "    for i, column_group in enumerate(starts_with):\n",
    "        similar_columns = [col for col in train.columns if col.startswith(column_group)]\n",
    "        if len(similar_columns) > 1:\n",
    "            divs = divisors(len(similar_columns))\n",
    "            if len(divs) % 2 == 0:\n",
    "                rows, cols = divs[(len(divs) // 2) - 1], divs[len(divs) // 2]\n",
    "            else:\n",
    "                rows, cols = divs[len(divs) // 2], divs[len(divs) // 2]\n",
    "            fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(40, 30), squeeze=False)\n",
    "            fig.suptitle(column_group, fontsize=25)\n",
    "            for j, column in enumerate(similar_columns):\n",
    "                x_cord, y_cord = divmod(j, cols)\n",
    "                train[column].plot(kind='box', ax=ax[x_cord, y_cord], fontsize=15)\n",
    "                # if column in ver.keys():\n",
    "                #     ax[x_cord, y_cord].axhline(y=ver.get(column)[0] * train[column].std(), color='green', label='down-limit')\n",
    "                #     ax[x_cord, y_cord].axhline(y=ver.get(column)[1] * train[column].std(), color='red', label='up-limit')\n",
    "                #     ax[x_cord, y_cord].legend(loc='best')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "vertical_columns = [col for col in X.columns if 'number_density' in col]\n",
    "# ver = dict(zip(vertical_columns, [(-5 * X[column].std(), 5 * X[column].std()) for column in vertical_columns]))\n",
    "\n",
    "# plot_boxplots()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7901bc4c9d7d1412",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Usunięcie wartości odstających"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a767724811d79e3c"
  },
  {
   "cell_type": "code",
   "source": [
    "def del_outliers():\n",
    "    for column in vertical_columns:\n",
    "        vec, indexes = zscore(X[column]), []\n",
    "        for j in range(len(vec)):\n",
    "            if -5 < vec[j] > 5:\n",
    "                indexes.append(j)\n",
    "        X.drop(index=indexes, inplace=True)\n",
    "        y.drop(index=indexes, inplace=True)\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        y.reset_index(drop=True, inplace=True)\n",
    "    return X\n",
    "\n",
    "\n",
    "# X = del_outliers()\n",
    "\n",
    "X.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e31da0f18fee574",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "X.head()",
   "metadata": {
    "collapsed": false
   },
   "id": "3463da86e8af6bd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Selekcja cech</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9161db0ea237c"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_feature_importance(sc, num_of_features):\n",
    "    if isinstance(sc, RFECV) or isinstance(sc, RFE):\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.ranking_))\n",
    "    else:\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.scores_))\n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:num_of_features]\n",
    "    scores_df = pd.DataFrame(scores, columns=['Feature', 'Score'])\n",
    "    \n",
    "    scores_df.plot(kind='bar', x='Feature', y='Score', figsize=(10, 6), rot=90, title='Oceny wybranych cech')\n",
    "    plt.xlabel('Cecha')\n",
    "    plt.ylabel('Ocena')\n",
    "\n",
    "\n",
    "# selector = RFE(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=700, \n",
    "#         max_depth=7, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True,\n",
    "#         warm_start=True\n",
    "#     ),\n",
    "#     n_features_to_select=k,\n",
    "# )\n",
    "# k = 17\n",
    "# selector = RFECV(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=400, \n",
    "#         max_depth=10, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True, \n",
    "#         warm_start=True, \n",
    "#         ccp_alpha=1e-4\n",
    "#     ),\n",
    "#     min_features_to_select=k, \n",
    "#     cv=10, \n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# selector.fit(X, y)\n",
    "# X, test = selector.transform(X), selector.transform(test)\n",
    "# \n",
    "# plot_feature_importance(selector, k)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c002ded9461774c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Transformacja danych</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8b9be23efdbd904"
  },
  {
   "cell_type": "markdown",
   "source": "### 1. Wybór sposobu preprocessingu danych",
   "metadata": {
    "collapsed": false
   },
   "id": "22bf5b75d8429019"
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X, y)\n",
    "test = scaler.transform(test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376c12ae9287f590",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Podział na zbiór testowy i treningowy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c70912092f074e4"
  },
  {
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)",
   "metadata": {
    "collapsed": false
   },
   "id": "683541f15475f393",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Część obliczeniowa</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea367ef409a37a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Otrzymanie najlepszych parametrów",
   "id": "9831b50f952a24eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_to_csv(y_pred, save_as):\n",
    "    final_df = pd.concat([test_ids, pd.DataFrame.from_dict({'pm2_5': y_pred})], axis=1)\n",
    "    final_df.to_csv(f'result\\\\{save_as}', index=False)"
   ],
   "id": "e9d2d344d5d30f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <center>PyTorch</center>",
   "id": "d8bd09cb2fae5106"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Wybór karty graficznej do nauki modelu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaf607cc44710975"
  },
  {
   "cell_type": "code",
   "source": [
    "# device = (\n",
    "#     'cuda'\n",
    "#     if torch.cuda.is_available()\n",
    "#     else 'mps'\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else 'cpu'\n",
    "# )\n",
    "# \n",
    "# X_train_tensor = torch.tensor(X_train, device=device, dtype=torch.float)\n",
    "# X_test_tensor = torch.tensor(X_test, device=device, dtype=torch.float)\n",
    "# y_train_tensor = torch.tensor(y_train.to_numpy(), device=device, dtype=torch.float)\n",
    "# y_test_tensor = torch.tensor(y_test.to_numpy(), device=device, dtype=torch.float)\n",
    "# test_tensor = torch.tensor(test, device=device, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ea7f2091127d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Optuna",
   "id": "6784e54b9ac8486f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def rmse_loss(y_true, y_pred):\n",
    "#     return torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "# \n",
    "# def define_model(trial):\n",
    "#     n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "#     layers = []\n",
    "#     \n",
    "#     in_features = X_train_tensor.shape[1]\n",
    "#     for i in range(n_layers):\n",
    "#         out_features = trial.suggest_int(f'layer{i}', 25, 200)\n",
    "#         layers.append(nn.Linear(in_features, out_features))\n",
    "#         layers.append(getattr(torch.nn, trial.suggest_categorical(f'nn_{i}', ['ReLU', 'Sigmoid', 'Tanh']))())\n",
    "#         layers.append(nn.Dropout(trial.suggest_float(f'dropout{i}', 0.1, 0.6)))\n",
    "#         in_features = out_features\n",
    "#     layers.append(nn.Linear(in_features, 1))\n",
    "#     return nn.Sequential(*layers)\n",
    "# \n",
    "# def objective(trial):\n",
    "#     model = define_model(trial).to(device=device)\n",
    "#     lr = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "#     weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-4)\n",
    "#     betas = (trial.suggest_float('beta1', 0.8, 0.9), trial.suggest_float('beta2', 0.997, 0.999))\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=betas, fused=True)\n",
    "#     \n",
    "#     batch_size = trial.suggest_int('batch_size', 16, 416, step=25)\n",
    "#     criterion = rmse_loss\n",
    "#     epochs = trial.suggest_int('epochs', 100, 300, step=50)\n",
    "#     \n",
    "#     final_train_tensor = torch.concat((X_train_tensor, y_train_tensor.unsqueeze(dim=1)), dim=1)\n",
    "#     dataset = DataLoader(final_train_tensor, batch_size=batch_size, shuffle=True)\n",
    "#     \n",
    "#     model.train()\n",
    "#     \n",
    "#     for epoch in range(epochs):\n",
    "#         epoch_loss = 0\n",
    "#         for batch_idx, batch in enumerate(dataset):\n",
    "#             inputs, targets = batch[:, :-1], batch[:, -1]\n",
    "#             batch_pred = model(inputs)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = criterion(targets, batch_pred.squeeze())\n",
    "#             epoch_loss += loss.item()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             \n",
    "#         trial.report(epoch_loss / len(dataset), epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.exceptions.TrialPruned()\n",
    "#         \n",
    "#     model.eval()\n",
    "#     \n",
    "#     with torch.no_grad():\n",
    "#         y_pred = model(X_test_tensor).squeeze()\n",
    "#         \n",
    "#     return root_mean_squared_error(y_test, y_pred.numpy(force=True))\n",
    "# \n",
    "# study = optuna.create_study(\n",
    "#     direction='minimize',\n",
    "#     sampler=optuna.samplers.TPESampler(),\n",
    "#     study_name='AirQuality',\n",
    "# )\n",
    "# study.optimize(objective, n_trials=200)\n",
    "# model_params = ['lr', 'n_layers', 'weight_decay', 'beta1', 'beta2', 'epochs', 'batch_size']"
   ],
   "id": "a612d991969930d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "def define_model(trial):\n",
    "    params = {\n",
    "        'objective': 'root_mean_squared_error',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 25),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 20),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-2, 2e-1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 900, 1100),\n",
    "        'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']),\n",
    "        # 'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 0.9, log=True),\n",
    "        # 'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 250),\n",
    "        'bagging_freq': 1,\n",
    "        'device': 'gpu',\n",
    "        'random_state': 4,\n",
    "        'verbosity': -1,\n",
    "        # 'extra_trees': True,\n",
    "    }\n",
    "    return lgb.LGBMRegressor(**params)\n",
    "\n",
    "def objective(trial):\n",
    "    lgbm = define_model(trial)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    y_pred = lgbm.predict(X_test)\n",
    "    return root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='AirQualityWithLightGBM')\n",
    "study.optimize(objective, n_trials=500)\n",
    "model_params = ['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'subsample', 'colsample_bytree', 'min_data_in_leaf']"
   ],
   "id": "21e4f067899ca658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający każdy <i>trial</i> w procesie nauki",
   "id": "7dd9e64e1b394237"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "8f7608eef0ccc810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wizualizacja przekroju parametrów",
   "id": "f9d8406114339ed0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_slice(study, params=model_params)",
   "id": "8142b6308c8970fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wielowymiarowe zależności parametrów",
   "id": "ac781e5abf8585da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_parallel_coordinate(study, params=model_params)",
   "id": "bf78850a6ed46b32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study.best_params",
   "id": "d4341655723aa9d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Do wysłania</center>",
   "id": "79bf1209e752a444"
  },
  {
   "cell_type": "code",
   "source": [
    "# best_model = define_model(study.best_trial)\n",
    "# best_model.to(device=device)\n",
    "# \n",
    "# best_model.eval()\n",
    "# \n",
    "# with torch.no_grad():\n",
    "#     save_to_csv(best_model(test_tensor).squeeze().numpy(force=True), 'nn.csv')\n",
    "\n",
    "best_model = define_model(study.best_trial)\n",
    "best_model.fit(X_train, y_train)\n",
    "save_to_csv(best_model.predict(test), 'lightgbm.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ce5044d06598de",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dodatkowe informacje\n",
    "<ol>\n",
    "    <li>The 15km SO2 band is ingested only when solar_zenith_angle < 70.</li>\n",
    "    <li>Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2128d77bca7e777"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
