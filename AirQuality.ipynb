{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Analiza poziomu PM2.5 w afrykańskich miastach</center>\n",
    "### Zespół:\n",
    "<ol>\n",
    "    <li style='font-size: 20px'>Hubert Kłosowski 242424</li>\n",
    "    <li style='font-size: 20px'>Krzysztof Kolanek 242425</li>\n",
    "    <li style='font-size: 20px'>Kamil Małecki 242464</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a096af4d2cacc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potrzebne importy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a57b6008c92140"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f44b8667be4021ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wczytanie danych"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c7a6517c9f58e8"
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('data\\\\train.csv')\n",
    "test = pd.read_csv('data\\\\test.csv')\n",
    "\n",
    "train.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8195eb62bb5596b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "train.head()",
   "metadata": {
    "collapsed": false
   },
   "id": "dcef3f3066b6dcaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rozbicie daty na składowe",
   "id": "af49ecab4176ea4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def change_date(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['day'] = dataframe['date'].dt.dayofweek.astype('category')\n",
    "    dataframe['month'] = dataframe['month'].astype('category')\n",
    "    dataframe['hour'] = dataframe['hour'].astype('category')\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "train, test = change_date(train), change_date(test)"
   ],
   "id": "96de3f55dc052fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający jakość powietrza w krajach afrykańskich",
   "id": "cdbb93a09da5579d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.lineplot(data=train, x='date', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza z podziałem na kraje')"
   ],
   "id": "c080d74ffd38ea41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 w zarejestrowanych godzinach",
   "id": "c18ec25179e58a3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='hour', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w poszczególnych godzinach z podziałem na kraje')"
   ],
   "id": "1cc187b6375c9eb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 z zależności od dnia tygodnia",
   "id": "e4b3fd78e799e096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='day', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "id": "36c6ec9520527975",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wartość pm2_5 z zależności od miesiąca",
   "id": "c018df974513e0e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.barplot(data=train, x='month', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "id": "18b6234a9ec5ca95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Korelacja wybranych kolumn z pm2_5",
   "id": "c2c34b8f0e6bf038"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.heatmap(train[['month', 'day', 'hour', 'site_latitude', 'site_longitude', 'cloud_surface_albedo', 'pm2_5']].corr(), annot=True, cmap='Greys')",
   "id": "e9964e42a6e9e51f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Czyszczenie danych</center>",
   "id": "ab3216061cba4b3a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Uzupełnienie wartości brakujących",
   "id": "ba2f9b8e1bcb96ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "\n",
    "def fill_train(column_name='site_latitude'):\n",
    "    column_values = X[column_name].unique()\n",
    "    for date in column_values:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [col for col in X.columns if col.startswith(column)]\n",
    "            df = X.loc[X[column_name] == date, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                try:\n",
    "                    X.loc[X[column_name] == date, similar_columns] = imputers[i].fit_transform(df, y)\n",
    "                except ValueError:\n",
    "                    X.drop(index=df.index, inplace=True)\n",
    "                    y.drop(index=df.index, inplace=True)\n",
    "                    X.reset_index(drop=True, inplace=True)\n",
    "                    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def fill_test(column_name='site_latitude'):\n",
    "    column_values = test[column_name].unique()\n",
    "    for date in column_values:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [col for col in test.columns if col.startswith(column)]\n",
    "            df = test.loc[test[column_name] == date, similar_columns].copy()\n",
    "            if not df.empty:\n",
    "                test.loc[test[column_name] == date, similar_columns] = imputers[i].transform(df)\n",
    "\n",
    "def drop_high_nans(dataframe):  # usuwamy kolumny o dużej liczbie wartości NaN\n",
    "    columns_nans = []\n",
    "    for i, el in enumerate(dataframe.columns):\n",
    "        if dataframe[el].isna().sum() / len(dataframe) >= 0.9:\n",
    "            columns_nans.append(el)\n",
    "    dataframe.drop(columns_nans, axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def drop_high_correlated_columns():\n",
    "    matrix = X.corr(numeric_only=True).abs()\n",
    "    upper_t = matrix.where(np.triu(np.ones_like(matrix, dtype=np.bool_), k=1))\n",
    "    return [col for col in upper_t.columns if any(upper_t[col] > 0.99)]\n",
    "\n",
    "\n",
    "test_ids = test['id']\n",
    "train.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "test.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "starts_with = train.columns.str.split('_', expand=True).levels[0].to_frame()\n",
    "starts_with.drop(['month', 'day', 'hour', 'pm2'], inplace=True)\n",
    "starts_with = starts_with[0].tolist()\n",
    "\n",
    "imputers = [KNNImputer(n_neighbors=15, weights='distance') for _ in range(len(starts_with))]\n",
    "# imputers = [IterativeImputer() for _ in range(len(starts_with))]\n",
    "X, y = train.drop(['pm2_5'], axis=1), train['pm2_5']\n",
    "X, test = drop_high_nans(X), drop_high_nans(test)\n",
    "# fill_train(), fill_test()\n",
    "# to_drop = drop_high_correlated_columns()\n",
    "# X, test = X.drop(columns=to_drop, axis=1), test.drop(columns=to_drop, axis=1)"
   ],
   "id": "133fbc1ffe6ae43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykresy pudełkowe wskazujące wartości odstające",
   "id": "9af06f017aaea4c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sympy import divisors\n",
    "\n",
    "\n",
    "def plot_boxplots():\n",
    "    for i, column_group in enumerate(starts_with):\n",
    "        similar_columns = [col for col in train.columns if col.startswith(column_group)]\n",
    "        if len(similar_columns) > 1:\n",
    "            divs = divisors(len(similar_columns))\n",
    "            if len(divs) % 2 == 0:\n",
    "                rows, cols = divs[(len(divs) // 2) - 1], divs[len(divs) // 2]\n",
    "            else:\n",
    "                rows, cols = divs[len(divs) // 2], divs[len(divs) // 2]\n",
    "            fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(40, 30), squeeze=False)\n",
    "            fig.suptitle(column_group, fontsize=25)\n",
    "            for j, column in enumerate(similar_columns):\n",
    "                x_cord, y_cord = divmod(j, cols)\n",
    "                train[column].plot(kind='box', ax=ax[x_cord, y_cord], fontsize=15)\n",
    "                if column in ver.keys():\n",
    "                    ax[x_cord, y_cord].axhline(y=ver.get(column)[0] * train[column].std(), color='green', label='down-limit')\n",
    "                    ax[x_cord, y_cord].axhline(y=ver.get(column)[1] * train[column].std(), color='red', label='up-limit')\n",
    "                    ax[x_cord, y_cord].legend(loc='best')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "vertical_columns = [col for col in X.columns if 'number_density' in col]\n",
    "ver = dict(zip(vertical_columns, [(-5 * X[column].std(), 5 * X[column].std()) for column in vertical_columns]))\n",
    "\n",
    "# plot_boxplots()"
   ],
   "id": "7901bc4c9d7d1412",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Usunięcie wartości odstających",
   "id": "a767724811d79e3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "def del_outliers():\n",
    "    zscores = zscore(X.select_dtypes(exclude='category').values, nan_policy='omit')\n",
    "    np.nan_to_num(zscores, copy=False)\n",
    "    zscores = np.absolute(zscores)\n",
    "    result = np.mean(zscores, axis=1)\n",
    "    indexes_to_drop = []\n",
    "    q1, q2 = np.quantile(result, 0.005), np.quantile(result, 0.995)\n",
    "    for i, el in enumerate(result):\n",
    "        if q1 <= el >= q2:\n",
    "            indexes_to_drop.append(i)\n",
    "    X.drop(indexes_to_drop, inplace=True)\n",
    "    y.drop(indexes_to_drop, inplace=True)\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# del_outliers()\n",
    "\n",
    "X.info()"
   ],
   "id": "e6ed493315daf808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.head()",
   "id": "1e31da0f18fee574",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Selekcja cech</center>",
   "id": "7a9161db0ea237c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest, mutual_info_regression, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def plot_feature_importance(sc, num_of_features):\n",
    "    if isinstance(sc, RFECV) or isinstance(sc, RFE):\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.ranking_))\n",
    "    else:\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.scores_))\n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:num_of_features]\n",
    "    scores_df = pd.DataFrame(scores, columns=['Feature', 'Score'])\n",
    "    \n",
    "    scores_df.plot(kind='bar', x='Feature', y='Score', figsize=(10, 6), rot=90, title='Oceny wybranych cech')\n",
    "    plt.xlabel('Cecha')\n",
    "    plt.ylabel('Ocena')\n",
    "\n",
    "\n",
    "# selector = RFE(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=700, \n",
    "#         max_depth=7, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True,\n",
    "#         warm_start=True\n",
    "#     ),\n",
    "#     n_features_to_select=k,\n",
    "# )\n",
    "# k = 17\n",
    "# selector = RFECV(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=400, \n",
    "#         max_depth=10, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True, \n",
    "#         warm_start=True, \n",
    "#         ccp_alpha=1e-4\n",
    "#     ),\n",
    "#     min_features_to_select=k, \n",
    "#     cv=10, \n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# selector.fit(X, y)\n",
    "# X, test = selector.transform(X), selector.transform(test)\n",
    "# \n",
    "# plot_feature_importance(selector, k)"
   ],
   "id": "c002ded9461774c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Transformacja danych</center>",
   "id": "a8b9be23efdbd904"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Standaryzacja danych",
   "id": "22bf5b75d8429019"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Bez kategorycznych\n",
    "# scale_columns = X.columns.difference(['hour', 'month', 'day'])\n",
    "# \n",
    "# scaler = make_column_transformer((StandardScaler(), scale_columns))\n",
    "# \n",
    "# X_cat, test_cat = X[['hour', 'month', 'day']], test[['hour', 'month', 'day']]\n",
    "# \n",
    "# X = pd.concat([pd.DataFrame(scaler.fit_transform(X[scale_columns]), columns=scaler.feature_names_in_), X_cat], axis=1)\n",
    "# test = pd.concat([pd.DataFrame(scaler.transform(test[scale_columns]), columns=scaler.feature_names_in_), test_cat], axis=1)\n",
    "# Wszyskie kolumny\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X, y)\n",
    "X = pd.DataFrame(X, columns=scaler.feature_names_in_)\n",
    "test = scaler.transform(test)"
   ],
   "id": "376c12ae9287f590",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Podział na zbiór walidacyjny i treningowy",
   "id": "5c70912092f074e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)"
   ],
   "id": "683541f15475f393",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Część obliczeniowa</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea367ef409a37a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Otrzymanie najlepszych parametrów",
   "id": "9831b50f952a24eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_to_csv(y_pred, save_as):\n",
    "    final_df = pd.concat([test_ids, pd.DataFrame.from_dict({'pm2_5': y_pred})], axis=1)\n",
    "    final_df.to_csv(f'result\\\\{save_as}', index=False)"
   ],
   "id": "e9d2d344d5d30f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Wybór karty graficznej dla PyTorcha",
   "metadata": {
    "collapsed": false
   },
   "id": "aaf607cc44710975"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# device = (\n",
    "#     'cuda'\n",
    "#     if torch.cuda.is_available()\n",
    "#     else 'mps'\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else 'cpu'\n",
    "# )\n",
    "# \n",
    "# X_train_tensor = torch.tensor(X_train, device=device, dtype=torch.float)\n",
    "# X_test_tensor = torch.tensor(X_test, device=device, dtype=torch.float)\n",
    "# y_train_tensor = torch.tensor(y_train.to_numpy(), device=device, dtype=torch.float)\n",
    "# y_test_tensor = torch.tensor(y_test.to_numpy(), device=device, dtype=torch.float)\n",
    "# test_tensor = torch.tensor(test, device=device, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ea7f2091127d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Optuna + Pytorch",
   "id": "6784e54b9ac8486f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def rmse_loss(y_true, y_pred):\n",
    "#     return torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "# \n",
    "# def define_model(trial):\n",
    "#     n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "#     layers = []\n",
    "#     \n",
    "#     in_features = X_train_tensor.shape[1]\n",
    "#     for i in range(n_layers):\n",
    "#         out_features = trial.suggest_int(f'layer{i}', 25, 200)\n",
    "#         layers.append(nn.Linear(in_features, out_features))\n",
    "#         layers.append(getattr(torch.nn, trial.suggest_categorical(f'nn_{i}', ['ReLU', 'Sigmoid', 'Tanh']))())\n",
    "#         layers.append(nn.Dropout(trial.suggest_float(f'dropout{i}', 0.1, 0.6)))\n",
    "#         in_features = out_features\n",
    "#     layers.append(nn.Linear(in_features, 1))\n",
    "#     return nn.Sequential(*layers)\n",
    "# \n",
    "# def objective(trial):\n",
    "#     model = define_model(trial).to(device=device)\n",
    "#     lr = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "#     weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-4)\n",
    "#     betas = (trial.suggest_float('beta1', 0.8, 0.9), trial.suggest_float('beta2', 0.997, 0.999))\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=betas, fused=True)\n",
    "#     \n",
    "#     batch_size = trial.suggest_int('batch_size', 16, 416, step=25)\n",
    "#     criterion = rmse_loss\n",
    "#     epochs = trial.suggest_int('epochs', 100, 300, step=50)\n",
    "#     \n",
    "#     final_train_tensor = torch.concat((X_train_tensor, y_train_tensor.unsqueeze(dim=1)), dim=1)\n",
    "#     dataset = DataLoader(final_train_tensor, batch_size=batch_size, shuffle=True)\n",
    "#     \n",
    "#     model.train()\n",
    "#     \n",
    "#     for epoch in range(epochs):\n",
    "#         epoch_loss = 0\n",
    "#         for batch_idx, batch in enumerate(dataset):\n",
    "#             inputs, targets = batch[:, :-1], batch[:, -1]\n",
    "#             batch_pred = model(inputs)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = criterion(targets, batch_pred.squeeze())\n",
    "#             epoch_loss += loss.item()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             \n",
    "#         trial.report(epoch_loss / len(dataset), epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.exceptions.TrialPruned()\n",
    "#         \n",
    "#     model.eval()\n",
    "#     \n",
    "#     with torch.no_grad():\n",
    "#         y_pred = model(X_test_tensor).squeeze()\n",
    "#         \n",
    "#     return root_mean_squared_error(y_test, y_pred.numpy(force=True))\n",
    "# \n",
    "# study = optuna.create_study(\n",
    "#     direction='minimize',\n",
    "#     sampler=optuna.samplers.TPESampler(),\n",
    "#     study_name='AirQuality',\n",
    "# )\n",
    "# study.optimize(objective, n_trials=200)\n",
    "# model_params = ['lr', 'n_layers', 'weight_decay', 'beta1', 'beta2', 'epochs', 'batch_size']"
   ],
   "id": "a612d991969930d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <center>Optuna + lightGBM</center>",
   "id": "f1951123b5b3569"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def define_lightgbm_model(trial):\n",
    "    params = {\n",
    "        'objective': 'root_mean_squared_error',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 15, 25),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 8e-3, 5e-2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 900, 1100),\n",
    "        'tree_learner': 'voting',\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 0.9),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 150),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 1e-8, 1, log=True),\n",
    "        'bagging_freq': 1,\n",
    "        'device': 'cpu',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 4,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    return lgb.LGBMRegressor(**params)\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    model = define_lightgbm_model(trial)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='AirQualityWithLightGBM', sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective_lightgbm, n_trials=500)"
   ],
   "id": "21e4f067899ca658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zdefiniowanie najlepszego lightgbm",
   "id": "54ba4a369bf8c70b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params_12 =  {'num_leaves': 25, \n",
    "           'max_depth': 15, \n",
    "           'learning_rate': 0.01982093884782807, \n",
    "           'n_estimators': 1042, \n",
    "           'tree_learner': 'voting', \n",
    "           'bagging_fraction': 0.863457680863147, \n",
    "           'subsample': 0.8572357579881347, \n",
    "           'colsample_bytree': 0.8692866219741755, \n",
    "           'min_data_in_leaf': 57,\n",
    "           'bagging_freq': 1,\n",
    "            'device': 'cpu',\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 4,\n",
    "            'verbosity': -1,\n",
    "           'objective': 'root_mean_squared_error',\n",
    "            'boosting_type': 'gbdt',\n",
    "           }\n",
    "# lgbm = lgb.LGBMRegressor(**params_12)\n",
    "lgbm = define_lightgbm_model(study.best_trial)\n",
    "lgbm.fit(X_train, y_train)\n",
    "model_params = ['num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'subsample', 'colsample_bytree', 'min_data_in_leaf', 'bagging_fraction']"
   ],
   "id": "d068d85105ef8d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "root_mean_squared_error(y_test, lgbm.predict(X_test))",
   "id": "cd0b3f5d0214f227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający każdy <i>trial</i> w procesie nauki",
   "id": "7dd9e64e1b394237"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "8f7608eef0ccc810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wizualizacja przekroju parametrów",
   "id": "f9d8406114339ed0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_slice(study, params=model_params)",
   "id": "8142b6308c8970fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wpływ poszczególnych parametrów na proces nauki modelu",
   "id": "b7670a4a8c62b011"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_param_importances(study)",
   "id": "6594be3641ad58f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Najlepsze parametry",
   "id": "a81fee2426d0cc68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study.best_params",
   "id": "d4341655723aa9d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Znaczenie poszczególnych kolumn",
   "id": "a7b518453e312064"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lgb.plot_importance(lgbm, figsize=(20, 12), dpi=200)",
   "id": "5a463c177c2dea71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Drzewo decyzyjne",
   "id": "3aa3b24cd053a042"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lgb.plot_tree(lgbm, precision=2, figsize=(20, 12), show_info=['data_percentage'], dpi=200, orientation='vertical')",
   "id": "bd6ab8ed5c9e4833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <center>Optuna + RandomForestRegressor</center>",
   "id": "ec02be0608d9aff4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def define_rfr_model(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 900),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 10, 50),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 50),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True]),\n",
    "        'oob_score': trial.suggest_categorical('oob_score', [True, False]),\n",
    "        'warm_start': trial.suggest_categorical('warm_start', [True, False]),\n",
    "        'random_state': 4,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "    return RandomForestRegressor(**params)\n",
    "\n",
    "def objective_rfr(trial):\n",
    "    model = define_rfr_model(trial)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='AirQualityWithRandomForestRegressor', sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective_rfr, n_trials=200)"
   ],
   "id": "dec6fe41d008823",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zdefiniowanie najlepszego RandomForestRegressor",
   "id": "5ac159f7995c8fa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rfr = define_rfr_model(study.best_trial)\n",
    "rfr.fit(X_train, y_train)"
   ],
   "id": "7014455ebd0fe1fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "root_mean_squared_error(y_test, rfr.predict(X_test))",
   "id": "ebac26f4a1b5aadf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Do wysłania</center>",
   "id": "79bf1209e752a444"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pytorch",
   "id": "f8dbc488d410fc79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# best_model = define_model(study.best_trial)\n",
    "# best_model.to(device=device)\n",
    "# \n",
    "# best_model.eval()\n",
    "# \n",
    "# with torch.no_grad():\n",
    "#     save_to_csv(best_model(test_tensor).squeeze().numpy(force=True), 'nn.csv')"
   ],
   "id": "701718bf3900dab9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### lightGBM",
   "id": "b18a5c8404b9bf18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_to_csv(lgbm.predict(test), 'lightgbm.csv')",
   "id": "74ce5044d06598de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RandomForestRegressor",
   "id": "d60e353a6810059b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_to_csv(rfr.predict(test), 'rfr.csv')",
   "id": "2293fbf00cd34490",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dodatkowe informacje\n",
    "<ol>\n",
    "    <li>The 15km SO2 band is ingested only when solar_zenith_angle < 70.</li>\n",
    "    <li>Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.</li>\n",
    "    <li>The effective cloud fraction is the radiometric equivalent cloud fraction of a satellite pixel assuming a fixed cloud albedo, usually 0.8. By definition the effective cloud fraction times the assumed cloud albedo plus the cloud-free surface and atmosphere contributions yields a TOA reflectance that agrees with the observed TOA reflectance.</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2128d77bca7e777"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
